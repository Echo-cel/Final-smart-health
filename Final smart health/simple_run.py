#!/usr/bin/env python3
"""
ç®€åŒ–çš„è¿è¡Œè„šæœ¬
"""

import os
import sys
import numpy as np
import cv2
import torch
import torch.nn as nn
import matplotlib.pyplot as plt
from datetime import datetime

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append('.')

def create_sample_data():
    """åˆ›å»ºç¤ºä¾‹æ•°æ®"""
    print("åˆ›å»ºç¤ºä¾‹æ•°æ®...")
    
    # åˆ›å»ºç›®å½•
    os.makedirs('data/processed/images', exist_ok=True)
    os.makedirs('data/processed/masks', exist_ok=True)
    os.makedirs('data/train/images', exist_ok=True)
    os.makedirs('data/train/masks', exist_ok=True)
    os.makedirs('data/val/images', exist_ok=True)
    os.makedirs('data/val/masks', exist_ok=True)
    os.makedirs('data/test/images', exist_ok=True)
    os.makedirs('data/test/masks', exist_ok=True)
    
    # åˆ›å»º20ä¸ªç¤ºä¾‹æ ·æœ¬
    for i in range(20):
        # åˆ›å»ºèƒŒæ™¯å›¾åƒ
        img = np.random.randint(180, 220, (512, 512, 3), dtype=np.uint8)
        
        # åˆ›å»ºæ©ç 
        mask = np.zeros((512, 512), dtype=np.uint8)
        
        # æ·»åŠ ç»†èƒæ ¸
        for _ in range(np.random.randint(5, 15)):
            center_x = np.random.randint(50, 462)
            center_y = np.random.randint(50, 462)
            radius = np.random.randint(10, 30)
            cv2.circle(mask, (center_x, center_y), radius, 255, -1)
            cv2.circle(img, (center_x, center_y), radius, (100, 100, 100), -1)
        
        # ä¿å­˜æ–‡ä»¶
        filename = f'sample_{i:03d}.png'
        
        # æ ¹æ®ç´¢å¼•åˆ†é…åˆ°ä¸åŒæ•°æ®é›†
        if i < 14:  # 70% è®­ç»ƒé›†
            cv2.imwrite(f'data/train/images/{filename}', img)
            cv2.imwrite(f'data/train/masks/{filename}', mask)
        elif i < 18:  # 20% éªŒè¯é›†
            cv2.imwrite(f'data/val/images/{filename}', img)
            cv2.imwrite(f'data/val/masks/{filename}', mask)
        else:  # 10% æµ‹è¯•é›†
            cv2.imwrite(f'data/test/images/{filename}', img)
            cv2.imwrite(f'data/test/masks/{filename}', mask)
    
    print("ç¤ºä¾‹æ•°æ®åˆ›å»ºå®Œæˆï¼")

def simple_transunet():
    """ç®€åŒ–çš„TransUNetæ¨¡å‹"""
    class SimpleTransUNet(nn.Module):
        def __init__(self):
            super().__init__()
            # ç®€åŒ–çš„ç¼–ç å™¨
            self.encoder = nn.Sequential(
                nn.Conv2d(3, 64, 3, padding=1),
                nn.ReLU(),
                nn.Conv2d(64, 64, 3, padding=1),
                nn.ReLU(),
                nn.MaxPool2d(2, 2)
            )
            
            # ç®€åŒ–çš„è§£ç å™¨
            self.decoder = nn.Sequential(
                nn.ConvTranspose2d(64, 32, 2, stride=2),
                nn.ReLU(),
                nn.Conv2d(32, 32, 3, padding=1),
                nn.ReLU(),
                nn.Conv2d(32, 1, 1)
            )
        
        def forward(self, x):
            x = self.encoder(x)
            x = self.decoder(x)
            return x
    
    return SimpleTransUNet()

def train_model():
    """è®­ç»ƒæ¨¡å‹"""
    print("å¼€å§‹è®­ç»ƒæ¨¡å‹...")
    
    # åˆ›å»ºæ¨¡å‹
    model = simple_transunet()
    criterion = nn.BCEWithLogitsLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    
    # åˆ›å»ºç®€å•çš„æ•°æ®åŠ è½½å™¨
    train_images = []
    train_masks = []
    
    # åŠ è½½è®­ç»ƒæ•°æ®
    for i in range(14):
        img_path = f'data/train/images/sample_{i:03d}.png'
        mask_path = f'data/train/masks/sample_{i:03d}.png'
        
        if os.path.exists(img_path) and os.path.exists(mask_path):
            img = cv2.imread(img_path)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            img = cv2.resize(img, (256, 256))
            img = img.astype(np.float32) / 255.0
            img = torch.from_numpy(img.transpose(2, 0, 1)).unsqueeze(0)
            
            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
            mask = cv2.resize(mask, (256, 256))
            mask = (mask > 127).astype(np.float32)
            mask = torch.from_numpy(mask).unsqueeze(0).unsqueeze(0)
            
            train_images.append(img)
            train_masks.append(mask)
    
    # è®­ç»ƒå‡ ä¸ªepoch
    model.train()
    for epoch in range(5):
        total_loss = 0
        for i, (img, mask) in enumerate(zip(train_images, train_masks)):
            optimizer.zero_grad()
            output = model(img)
            loss = criterion(output, mask)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        
        print(f"Epoch {epoch+1}, Loss: {total_loss/len(train_images):.4f}")
    
    print("è®­ç»ƒå®Œæˆï¼")
    return model

def evaluate_model(model):
    """è¯„ä¼°æ¨¡å‹"""
    print("è¯„ä¼°æ¨¡å‹...")
    
    model.eval()
    test_images = []
    test_masks = []
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    for i in range(18, 20):
        img_path = f'data/test/images/sample_{i:03d}.png'
        mask_path = f'data/test/masks/sample_{i:03d}.png'
        
        if os.path.exists(img_path) and os.path.exists(mask_path):
            img = cv2.imread(img_path)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            img = cv2.resize(img, (256, 256))
            img = img.astype(np.float32) / 255.0
            img = torch.from_numpy(img.transpose(2, 0, 1)).unsqueeze(0)
            
            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
            mask = cv2.resize(mask, (256, 256))
            mask = (mask > 127).astype(np.float32)
            mask = torch.from_numpy(mask).unsqueeze(0).unsqueeze(0)
            
            test_images.append(img)
            test_masks.append(mask)
    
    # è®¡ç®—Diceç³»æ•°
    dice_scores = []
    with torch.no_grad():
        for img, mask in zip(test_images, test_masks):
            output = model(img)
            pred = torch.sigmoid(output) > 0.5
            
            intersection = (pred * mask).sum()
            union = pred.sum() + mask.sum()
            dice = (2 * intersection) / (union + 1e-6)
            dice_scores.append(dice.item())
    
    avg_dice = np.mean(dice_scores)
    print(f"å¹³å‡Diceç³»æ•°: {avg_dice:.4f}")
    
    return avg_dice

def visualize_results(model):
    """å¯è§†åŒ–ç»“æœ"""
    print("ç”Ÿæˆå¯è§†åŒ–ç»“æœ...")
    
    os.makedirs('results', exist_ok=True)
    
    # åŠ è½½ä¸€ä¸ªæµ‹è¯•æ ·æœ¬
    img_path = 'data/test/images/sample_018.png'
    mask_path = 'data/test/masks/sample_018.png'
    
    if os.path.exists(img_path) and os.path.exists(mask_path):
        # åŠ è½½å›¾åƒ
        img = cv2.imread(img_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img_resized = cv2.resize(img, (256, 256))
        
        # åŠ è½½æ©ç 
        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        mask_resized = cv2.resize(mask, (256, 256))
        mask_binary = (mask_resized > 127).astype(np.uint8) * 255
        
        # é¢„æµ‹
        model.eval()
        with torch.no_grad():
            img_tensor = torch.from_numpy(img_resized.astype(np.float32) / 255.0).permute(2, 0, 1).unsqueeze(0)
            output = model(img_tensor)
            pred = torch.sigmoid(output) > 0.5
            pred_mask = pred.squeeze().numpy().astype(np.uint8) * 255
        
        # å¯è§†åŒ–
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        
        axes[0].imshow(img_resized)
        axes[0].set_title('åŸå§‹å›¾åƒ')
        axes[0].axis('off')
        
        axes[1].imshow(mask_binary, cmap='gray')
        axes[1].set_title('çœŸå®æ©ç ')
        axes[1].axis('off')
        
        axes[2].imshow(pred_mask, cmap='gray')
        axes[2].set_title('é¢„æµ‹æ©ç ')
        axes[2].axis('off')
        
        plt.tight_layout()
        plt.savefig('results/sample_results.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print("å¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ° results/sample_results.png")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¥ æ™ºæ…§åŒ»ç–— - åŒ»å­¦å›¾åƒåˆ†å‰²é¡¹ç›®")
    print("=" * 50)
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # æ­¥éª¤1: åˆ›å»ºç¤ºä¾‹æ•°æ®
    create_sample_data()
    
    # æ­¥éª¤2: è®­ç»ƒæ¨¡å‹
    model = train_model()
    
    # æ­¥éª¤3: è¯„ä¼°æ¨¡å‹
    dice_score = evaluate_model(model)
    
    # æ­¥éª¤4: å¯è§†åŒ–ç»“æœ
    visualize_results(model)
    
    print("\n" + "="*50)
    print("ğŸ‰ é¡¹ç›®è¿è¡Œå®Œæˆï¼")
    print("="*50)
    print(f"æœ€ç»ˆDiceç³»æ•°: {dice_score:.4f}")
    print("ç»“æœæ–‡ä»¶: results/sample_results.png")
    print(f"ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

if __name__ == '__main__':
    main() 