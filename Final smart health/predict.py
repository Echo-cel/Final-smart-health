#!/usr/bin/env python3
"""
MoNuSegç»†èƒæ ¸åˆ†å‰²é¢„æµ‹è„šæœ¬
"""

import os
import sys
import numpy as np
import cv2
import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt
from datetime import datetime
import glob
from tqdm import tqdm

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append('.')

class MoNuSegTransUNet(torch.nn.Module):
    """é’ˆå¯¹MoNuSegä¼˜åŒ–çš„TransUNetæ¨¡å‹"""
    def __init__(self, img_size=512, in_channels=3, out_channels=1):
        super().__init__()
        
        # ç¼–ç å™¨
        self.enc1 = torch.nn.Sequential(
            torch.nn.Conv2d(in_channels, 64, 3, padding=1),
            torch.nn.BatchNorm2d(64),
            torch.nn.ReLU(inplace=True),
            torch.nn.Conv2d(64, 64, 3, padding=1),
            torch.nn.BatchNorm2d(64),
            torch.nn.ReLU(inplace=True)
        )
        
        self.enc2 = torch.nn.Sequential(
            torch.nn.MaxPool2d(2, 2),
            torch.nn.Conv2d(64, 128, 3, padding=1),
            torch.nn.BatchNorm2d(128),
            torch.nn.ReLU(inplace=True),
            torch.nn.Conv2d(128, 128, 3, padding=1),
            torch.nn.BatchNorm2d(128),
            torch.nn.ReLU(inplace=True)
        )
        
        self.enc3 = torch.nn.Sequential(
            torch.nn.MaxPool2d(2, 2),
            torch.nn.Conv2d(128, 256, 3, padding=1),
            torch.nn.BatchNorm2d(256),
            torch.nn.ReLU(inplace=True),
            torch.nn.Conv2d(256, 256, 3, padding=1),
            torch.nn.BatchNorm2d(256),
            torch.nn.ReLU(inplace=True)
        )
        
        self.enc4 = torch.nn.Sequential(
            torch.nn.MaxPool2d(2, 2),
            torch.nn.Conv2d(256, 512, 3, padding=1),
            torch.nn.BatchNorm2d(512),
            torch.nn.ReLU(inplace=True),
            torch.nn.Conv2d(512, 512, 3, padding=1),
            torch.nn.BatchNorm2d(512),
            torch.nn.ReLU(inplace=True)
        )
        
        # è§£ç å™¨
        self.dec4 = torch.nn.Sequential(
            torch.nn.ConvTranspose2d(512, 256, 2, stride=2),
            torch.nn.BatchNorm2d(256),
            torch.nn.ReLU(inplace=True),
            torch.nn.Conv2d(256, 256, 3, padding=1),
            torch.nn.BatchNorm2d(256),
            torch.nn.ReLU(inplace=True)
        )
        
        self.dec3 = torch.nn.Sequential(
            torch.nn.ConvTranspose2d(512, 128, 2, stride=2),
            torch.nn.BatchNorm2d(128),
            torch.nn.ReLU(inplace=True),
            torch.nn.Conv2d(128, 128, 3, padding=1),
            torch.nn.BatchNorm2d(128),
            torch.nn.ReLU(inplace=True)
        )
        
        self.dec2 = torch.nn.Sequential(
            torch.nn.ConvTranspose2d(256, 64, 2, stride=2),
            torch.nn.BatchNorm2d(64),
            torch.nn.ReLU(inplace=True),
            torch.nn.Conv2d(64, 64, 3, padding=1),
            torch.nn.BatchNorm2d(64),
            torch.nn.ReLU(inplace=True)
        )
        
        self.dec1 = torch.nn.Sequential(
            torch.nn.ConvTranspose2d(128, 32, 2, stride=2),
            torch.nn.BatchNorm2d(32),
            torch.nn.ReLU(inplace=True),
            torch.nn.Conv2d(32, 32, 3, padding=1),
            torch.nn.BatchNorm2d(32),
            torch.nn.ReLU(inplace=True)
        )
        
        # æœ€ç»ˆè¾“å‡ºå±‚
        self.final_conv = torch.nn.Conv2d(32, out_channels, kernel_size=1)

    def forward(self, x):
        input_size = x.size()[2:]
        enc1 = self.enc1(x)
        enc2 = self.enc2(enc1)
        enc3 = self.enc3(enc2)
        enc4 = self.enc4(enc3)
        dec4 = self.dec4(enc4)
        # å¯¹é½enc3å°ºå¯¸
        if dec4.shape[2:] != enc3.shape[2:]:
            dec4 = F.interpolate(dec4, size=enc3.shape[2:], mode='bilinear', align_corners=False)
        dec4 = torch.cat([dec4, enc3], dim=1)
        dec3 = self.dec3(dec4)
        if dec3.shape[2:] != enc2.shape[2:]:
            dec3 = F.interpolate(dec3, size=enc2.shape[2:], mode='bilinear', align_corners=False)
        dec3 = torch.cat([dec3, enc2], dim=1)
        dec2 = self.dec2(dec3)
        if dec2.shape[2:] != enc1.shape[2:]:
            dec2 = F.interpolate(dec2, size=enc1.shape[2:], mode='bilinear', align_corners=False)
        dec2 = torch.cat([dec2, enc1], dim=1)
        dec1 = self.dec1(dec2)
        # è¾“å‡ºresizeåˆ°è¾“å…¥å°ºå¯¸
        if dec1.shape[2:] != input_size:
            dec1 = F.interpolate(dec1, size=input_size, mode='bilinear', align_corners=False)
        output = self.final_conv(dec1)
        return output

def load_model(model_path='best_model.pth'):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    print(f"åŠ è½½æ¨¡å‹: {model_path}")
    
    if not os.path.exists(model_path):
        print(f"é”™è¯¯: æ¨¡å‹æ–‡ä»¶ {model_path} ä¸å­˜åœ¨!")
        print("è¯·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬ç”Ÿæˆæ¨¡å‹æ–‡ä»¶")
        return None
    
    # åˆ›å»ºæ¨¡å‹
    model = MoNuSegTransUNet(img_size=512, in_channels=3, out_channels=1)
    
    # åŠ è½½æƒé‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.load_state_dict(torch.load(model_path, map_location=device))
    model = model.to(device)
    model.eval()
    
    print(f"æ¨¡å‹åŠ è½½æˆåŠŸï¼Œä½¿ç”¨è®¾å¤‡: {device}")
    return model

def preprocess_image(image_path, target_size=512):
    """é¢„å¤„ç†è¾“å…¥å›¾åƒ"""
    # è¯»å–å›¾åƒ
    image = cv2.imread(image_path)
    if image is None:
        print(f"é”™è¯¯: æ— æ³•è¯»å–å›¾åƒ {image_path}")
        return None
    
    # è½¬æ¢ä¸ºRGB
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    # ä¿å­˜åŸå§‹å°ºå¯¸
    original_size = image.shape[:2]
    
    # è°ƒæ•´å°ºå¯¸
    image_resized = cv2.resize(image, (target_size, target_size))
    
    # æ ‡å‡†åŒ–
    image_normalized = image_resized.astype(np.float32) / 255.0
    
    return {
        'original': image,
        'resized': image_resized,
        'normalized': image_normalized,
        'original_size': original_size
    }

def predict_single_image(model, image_data, threshold=0.5):
    """å¯¹å•å¼ å›¾åƒè¿›è¡Œé¢„æµ‹"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # å‡†å¤‡è¾“å…¥
    image_tensor = torch.from_numpy(image_data['normalized'].transpose(2, 0, 1)).unsqueeze(0).to(device)
    
    # é¢„æµ‹
    with torch.no_grad():
        output = model(image_tensor)
        prob = torch.sigmoid(output)
        pred_mask = (prob > threshold).float()
    
    # è½¬æ¢ä¸ºnumpy
    pred_mask = pred_mask.squeeze().cpu().numpy().astype(np.uint8) * 255
    
    # è°ƒæ•´å›åŸå§‹å°ºå¯¸
    pred_mask_resized = cv2.resize(pred_mask, (image_data['original_size'][1], image_data['original_size'][0]))
    
    return {
        'probability': prob.squeeze().cpu().numpy(),
        'mask': pred_mask,
        'mask_resized': pred_mask_resized
    }

def visualize_prediction(image_data, prediction, save_path=None):
    """å¯è§†åŒ–é¢„æµ‹ç»“æœ"""
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    
    # åŸå§‹å›¾åƒ
    axes[0].imshow(image_data['original'])
    axes[0].set_title('Original Image')
    axes[0].axis('off')
    
    # æ¦‚ç‡å›¾
    axes[1].imshow(prediction['probability'], cmap='hot')
    axes[1].set_title('Prediction Probability')
    axes[1].axis('off')
    
    # åˆ†å‰²æ©ç 
    axes[2].imshow(prediction['mask'], cmap='gray')
    axes[2].set_title('Segmentation Mask')
    axes[2].axis('off')
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"ç»“æœå·²ä¿å­˜åˆ°: {save_path}")
    
    plt.show()

def predict_batch_images(model, image_dir, output_dir='predictions'):
    """æ‰¹é‡é¢„æµ‹å›¾åƒ"""
    print(f"æ‰¹é‡é¢„æµ‹å›¾åƒç›®å½•: {image_dir}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # æ”¯æŒçš„å›¾åƒæ ¼å¼
    image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.tif', '*.tiff', '*.bmp']
    image_files = []
    
    for ext in image_extensions:
        image_files.extend(glob.glob(os.path.join(image_dir, ext)))
        image_files.extend(glob.glob(os.path.join(image_dir, ext.upper())))
    
    if not image_files:
        print(f"åœ¨ç›®å½• {image_dir} ä¸­æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
        return
    
    print(f"æ‰¾åˆ° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶")
    
    results = []
    
    for image_path in tqdm(image_files, desc="é¢„æµ‹ä¸­"):
        try:
            # é¢„å¤„ç†å›¾åƒ
            image_data = preprocess_image(image_path)
            if image_data is None:
                continue
            
            # é¢„æµ‹
            prediction = predict_single_image(model, image_data)
            
            # ä¿å­˜ç»“æœ
            base_name = os.path.splitext(os.path.basename(image_path))[0]
            save_path = os.path.join(output_dir, f"{base_name}_prediction.png")
            
            # å¯è§†åŒ–å¹¶ä¿å­˜
            visualize_prediction(image_data, prediction, save_path)
            
            # ä¿å­˜æ©ç 
            mask_path = os.path.join(output_dir, f"{base_name}_mask.png")
            cv2.imwrite(mask_path, prediction['mask_resized'])
            
            results.append({
                'image_path': image_path,
                'prediction_path': save_path,
                'mask_path': mask_path
            })
            
        except Exception as e:
            print(f"å¤„ç†å›¾åƒ {image_path} æ—¶å‡ºé”™: {e}")
    
    print(f"æ‰¹é‡é¢„æµ‹å®Œæˆï¼Œå…±å¤„ç† {len(results)} ä¸ªå›¾åƒ")
    return results

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¬ MoNuSegç»†èƒæ ¸åˆ†å‰²é¢„æµ‹ç³»ç»Ÿ")
    print("=" * 50)
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # åŠ è½½æ¨¡å‹
    model = load_model()
    if model is None:
        return
    
    print("\nè¯·é€‰æ‹©é¢„æµ‹æ¨¡å¼:")
    print("1. å•å¼ å›¾åƒé¢„æµ‹")
    print("2. æ‰¹é‡å›¾åƒé¢„æµ‹")
    print("3. ä½¿ç”¨æµ‹è¯•æ•°æ®é¢„æµ‹")
    
    choice = input("è¯·è¾“å…¥é€‰æ‹© (1/2/3): ").strip()
    
    if choice == "1":
        # å•å¼ å›¾åƒé¢„æµ‹
        image_path = input("è¯·è¾“å…¥å›¾åƒè·¯å¾„: ").strip()
        if not os.path.exists(image_path):
            print("å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨!")
            return
        
        # é¢„å¤„ç†å›¾åƒ
        image_data = preprocess_image(image_path)
        if image_data is None:
            return
        
        # é¢„æµ‹
        prediction = predict_single_image(model, image_data)
        
        # å¯è§†åŒ–ç»“æœ
        visualize_prediction(image_data, prediction, 'results/single_prediction.png')
        
        # ä¿å­˜æ©ç 
        cv2.imwrite('results/single_prediction_mask.png', prediction['mask_resized'])
        print("é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ° results/ ç›®å½•")
        
    elif choice == "2":
        # æ‰¹é‡é¢„æµ‹
        image_dir = input("è¯·è¾“å…¥å›¾åƒç›®å½•è·¯å¾„: ").strip()
        if not os.path.exists(image_dir):
            print("ç›®å½•ä¸å­˜åœ¨!")
            return
        
        results = predict_batch_images(model, image_dir)
        
    elif choice == "3":
        # ä½¿ç”¨æµ‹è¯•æ•°æ®é¢„æµ‹
        test_dir = "data/MoNuSegTestData"
        if not os.path.exists(test_dir):
            print("æµ‹è¯•æ•°æ®ç›®å½•ä¸å­˜åœ¨!")
            return
        
        print(f"ä½¿ç”¨æµ‹è¯•æ•°æ®ç›®å½•: {test_dir}")
        results = predict_batch_images(model, test_dir, 'results/test_predictions')
        
    else:
        print("æ— æ•ˆé€‰æ‹©!")
        return
    
    print("\n" + "="*50)
    print("ğŸ‰ é¢„æµ‹å®Œæˆï¼")
    print("="*50)
    print(f"ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

if __name__ == '__main__':
    main() 