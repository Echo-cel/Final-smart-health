#!/usr/bin/env python3
"""
æ™ºæ…§åŒ»ç–— - åŒ»å­¦å›¾åƒåˆ†å‰²é¡¹ç›®æ¼”ç¤ºè„šæœ¬

è¿™ä¸ªè„šæœ¬æ¼”ç¤ºäº†å®Œæ•´çš„é¡¹ç›®è¿è¡Œæµç¨‹ï¼š
1. æ•°æ®é¢„å¤„ç†
2. æ¨¡å‹è®­ç»ƒ
3. æ¨¡å‹è¯„ä¼°
4. ç»“æœå¯è§†åŒ–
"""

import os
import sys
import subprocess
import time
from datetime import datetime

def run_command(command, description):
    """è¿è¡Œå‘½ä»¤å¹¶æ˜¾ç¤ºè¿›åº¦"""
    print(f"\n{'='*60}")
    print(f"æ­£åœ¨æ‰§è¡Œ: {description}")
    print(f"å‘½ä»¤: {command}")
    print(f"{'='*60}")
    
    start_time = time.time()
    
    try:
        result = subprocess.run(command, shell=True, check=True, capture_output=True, text=True)
        end_time = time.time()
        
        print(f"âœ… {description} å®Œæˆï¼è€—æ—¶: {end_time - start_time:.2f}ç§’")
        if result.stdout:
            print("è¾“å‡º:")
            print(result.stdout)
        
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ {description} å¤±è´¥ï¼")
        print(f"é”™è¯¯ä¿¡æ¯: {e.stderr}")
        return False

def check_dependencies():
    """æ£€æŸ¥ä¾èµ–åŒ…"""
    print("æ£€æŸ¥é¡¹ç›®ä¾èµ–...")
    
    required_packages = [
        'torch', 'torchvision', 'numpy', 'opencv-python', 
        'Pillow', 'albumentations', 'matplotlib', 'tensorboard',
        'scikit-image', 'scipy', 'tqdm', 'PyYAML', 'seaborn', 'pandas'
    ]
    
    missing_packages = []
    
    for package in required_packages:
        try:
            __import__(package.replace('-', '_'))
        except ImportError:
            missing_packages.append(package)
    
    if missing_packages:
        print(f"âŒ ç¼ºå°‘ä»¥ä¸‹ä¾èµ–åŒ…: {', '.join(missing_packages)}")
        print("è¯·è¿è¡Œ: pip install -r requirements.txt")
        return False
    
    print("âœ… æ‰€æœ‰ä¾èµ–åŒ…å·²å®‰è£…")
    return True

def create_directories():
    """åˆ›å»ºå¿…è¦çš„ç›®å½•"""
    directories = [
        'data', 'data/raw', 'data/processed', 'data/splits',
        'checkpoints', 'logs', 'results'
    ]
    
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
    
    print("âœ… ç›®å½•ç»“æ„åˆ›å»ºå®Œæˆ")

def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸ¥ æ™ºæ…§åŒ»ç–— - åŒ»å­¦å›¾åƒåˆ†å‰²é¡¹ç›®æ¼”ç¤º")
    print("=" * 60)
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        return
    
    # åˆ›å»ºç›®å½•
    create_directories()
    
    # æ­¥éª¤1: åˆ›å»ºç¤ºä¾‹æ•°æ®
    print("\nğŸ“Š æ­¥éª¤1: åˆ›å»ºç¤ºä¾‹æ•°æ®")
    if not run_command(
        "python utils/preprocess.py --create_samples --num_samples 50 --split",
        "åˆ›å»ºç¤ºä¾‹æ•°æ®å¹¶åˆ’åˆ†æ•°æ®é›†"
    ):
        print("âŒ æ•°æ®åˆ›å»ºå¤±è´¥ï¼Œé€€å‡ºæ¼”ç¤º")
        return
    
    # æ­¥éª¤2: è®­ç»ƒæ¨¡å‹ï¼ˆä½¿ç”¨è¾ƒå°‘çš„epochè¿›è¡Œæ¼”ç¤ºï¼‰
    print("\nğŸ¤– æ­¥éª¤2: è®­ç»ƒæ¨¡å‹")
    
    # ä¿®æ”¹é…ç½®æ–‡ä»¶ä»¥ä½¿ç”¨è¾ƒå°‘çš„epochè¿›è¡Œæ¼”ç¤º
    config_content = """# æ•°æ®é›†é…ç½®
dataset:
  name: "MoNuSeg"
  image_size: 512
  num_classes: 1
  train_split: 0.7
  val_split: 0.2
  test_split: 0.1

# æ¨¡å‹é…ç½®
model:
  name: "TransUNet"
  in_channels: 3
  out_channels: 1
  embed_dim: 768
  patch_size: 16
  num_heads: 12
  num_layers: 12
  mlp_ratio: 4.0
  dropout: 0.1

# è®­ç»ƒé…ç½®ï¼ˆæ¼”ç¤ºç”¨ï¼Œå‡å°‘epochæ•°ï¼‰
training:
  batch_size: 2
  num_epochs: 10
  learning_rate: 0.0001
  weight_decay: 0.0001
  optimizer: "Adam"
  scheduler: "CosineAnnealingLR"
  loss_function: "DiceBCELoss"
  
# æ•°æ®å¢å¼ºé…ç½®
augmentation:
  horizontal_flip_prob: 0.5
  vertical_flip_prob: 0.5
  rotation_limit: 30
  brightness_limit: 0.2
  contrast_limit: 0.2
  gaussian_noise_var: 0.01
  elastic_transform_alpha: 1
  elastic_transform_sigma: 50

# è·¯å¾„é…ç½®
paths:
  data_dir: "data"
  raw_data_dir: "data/raw"
  processed_data_dir: "data/processed"
  splits_dir: "data/splits"
  checkpoints_dir: "checkpoints"
  logs_dir: "logs"
  results_dir: "results"

# å…¶ä»–é…ç½®
misc:
  seed: 42
  num_workers: 2
  device: "cuda"
  save_freq: 5
  log_freq: 50
"""
    
    with open('configs/config.yaml', 'w', encoding='utf-8') as f:
        f.write(config_content)
    
    if not run_command("python train.py", "è®­ç»ƒTransUNetæ¨¡å‹"):
        print("âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥ï¼Œä½†ç»§ç»­æ¼”ç¤ºå…¶ä»–æ­¥éª¤")
    
    # æ­¥éª¤3: è¯„ä¼°æ¨¡å‹
    print("\nğŸ“ˆ æ­¥éª¤3: è¯„ä¼°æ¨¡å‹")
    if not run_command("python evaluate.py", "è¯„ä¼°æ¨¡å‹æ€§èƒ½"):
        print("âŒ æ¨¡å‹è¯„ä¼°å¤±è´¥")
    
    # æ­¥éª¤4: å¯è§†åŒ–ç»“æœ
    print("\nğŸ¨ æ­¥éª¤4: å¯è§†åŒ–ç»“æœ")
    if not run_command("python visualize.py", "ç”Ÿæˆå¯è§†åŒ–ç»“æœ"):
        print("âŒ å¯è§†åŒ–å¤±è´¥")
    
    # æ˜¾ç¤ºç»“æœ
    print("\n" + "="*60)
    print("ğŸ‰ æ¼”ç¤ºå®Œæˆï¼")
    print("="*60)
    
    print("\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
    print("  - checkpoints/: æ¨¡å‹æ£€æŸ¥ç‚¹")
    print("  - logs/: TensorBoardæ—¥å¿—")
    print("  - results/: è¯„ä¼°ç»“æœå’Œå¯è§†åŒ–")
    print("  - data/: æ•°æ®é›†")
    
    print("\nğŸ“Š æŸ¥çœ‹ç»“æœ:")
    print("  - è®­ç»ƒæ›²çº¿: results/training_curves.png")
    print("  - æ ·æœ¬ç»“æœ: results/sample_results.png")
    print("  - è¯„ä¼°æŒ‡æ ‡: results/evaluation_results.csv")
    print("  - ç»¼åˆæŠ¥å‘Š: results/comprehensive_report.html")
    
    print("\nğŸ” ä½¿ç”¨TensorBoardæŸ¥çœ‹è®­ç»ƒè¿‡ç¨‹:")
    print("  tensorboard --logdir logs")
    
    print(f"\nç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç»“æœæ–‡ä»¶
    result_files = [
        'results/training_curves.png',
        'results/sample_results.png',
        'results/evaluation_results.csv',
        'results/comprehensive_report.html'
    ]
    
    print("\nğŸ“‹ ç»“æœæ–‡ä»¶æ£€æŸ¥:")
    for file_path in result_files:
        if os.path.exists(file_path):
            print(f"  âœ… {file_path}")
        else:
            print(f"  âŒ {file_path} (æœªç”Ÿæˆ)")

if __name__ == '__main__':
    main() 