#!/usr/bin/env python3
"""
MoNuSegæ•°æ®é›†å¤„ç†è„šæœ¬
"""

import os
import sys
import numpy as np
import cv2
import torch
import torch.nn as nn
import torch.nn.functional as F
import matplotlib.pyplot as plt
import xml.etree.ElementTree as ET
from datetime import datetime
import glob
from tqdm import tqdm

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append('.')

def parse_xml_annotation(xml_path):
    """è§£æXMLæ ‡æ³¨æ–‡ä»¶ï¼Œæå–ç»†èƒæ ¸åæ ‡"""
    tree = ET.parse(xml_path)
    root = tree.getroot()
    
    nuclei = []
    for annotation in root.findall('.//Annotation'):
        for region in annotation.findall('.//Region'):
            vertices = []
            for vertex in region.findall('.//Vertex'):
                x = float(vertex.get('X'))
                y = float(vertex.get('Y'))
                vertices.append([x, y])
            
            if len(vertices) > 2:  # è‡³å°‘éœ€è¦3ä¸ªç‚¹å½¢æˆå¤šè¾¹å½¢
                nuclei.append(np.array(vertices))
    
    return nuclei

def create_mask_from_nuclei(nuclei, image_shape):
    """ä»ç»†èƒæ ¸åæ ‡åˆ›å»ºæ©ç """
    mask = np.zeros(image_shape[:2], dtype=np.uint8)
    
    for nucleus in nuclei:
        # å°†åæ ‡è½¬æ¢ä¸ºæ•´æ•°
        nucleus_int = nucleus.astype(np.int32)
        # å¡«å……å¤šè¾¹å½¢
        cv2.fillPoly(mask, [nucleus_int], 255)
    
    return mask

def load_monuseg_data(data_dir, is_training=True):
    """åŠ è½½MoNuSegæ•°æ®"""
    print(f"åŠ è½½{'è®­ç»ƒ' if is_training else 'æµ‹è¯•'}æ•°æ®...")
    
    if is_training:
        images_dir = os.path.join(data_dir, "MoNuSeg 2018 Training Data", "Tissue Images")
        annotations_dir = os.path.join(data_dir, "MoNuSeg 2018 Training Data", "Annotations")
    else:
        # æµ‹è¯•æ•°æ®åœ¨åŒä¸€ç›®å½•ä¸‹
        images_dir = data_dir
        annotations_dir = data_dir
    
    # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
    image_files = glob.glob(os.path.join(images_dir, "*.tif"))
    
    data_pairs = []
    
    for img_path in tqdm(image_files, desc="å¤„ç†æ•°æ®"):
        # è·å–å¯¹åº”çš„XMLæ–‡ä»¶
        base_name = os.path.splitext(os.path.basename(img_path))[0]
        xml_path = os.path.join(annotations_dir, f"{base_name}.xml")
        
        if os.path.exists(xml_path):
            # è¯»å–å›¾åƒ
            image = cv2.imread(img_path)
            if image is None:
                continue
            
            # è½¬æ¢ä¸ºRGB
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # è§£æXMLæ ‡æ³¨
            nuclei = parse_xml_annotation(xml_path)
            
            # åˆ›å»ºæ©ç 
            mask = create_mask_from_nuclei(nuclei, image.shape)
            
            data_pairs.append({
                'image': image,
                'mask': mask,
                'image_path': img_path,
                'xml_path': xml_path
            })
    
    print(f"æˆåŠŸåŠ è½½ {len(data_pairs)} ä¸ªæ ·æœ¬")
    return data_pairs

def preprocess_data(data_pairs, target_size=512):
    """é¢„å¤„ç†æ•°æ®"""
    print("é¢„å¤„ç†æ•°æ®...")
    
    processed_data = []
    
    for pair in tqdm(data_pairs, desc="é¢„å¤„ç†"):
        image = pair['image']
        mask = pair['mask']
        
        # è°ƒæ•´å›¾åƒå°ºå¯¸
        image_resized = cv2.resize(image, (target_size, target_size))
        mask_resized = cv2.resize(mask, (target_size, target_size))
        
        # æ ‡å‡†åŒ–å›¾åƒ
        image_normalized = image_resized.astype(np.float32) / 255.0
        
        # äºŒå€¼åŒ–æ©ç 
        mask_binary = (mask_resized > 127).astype(np.uint8) * 255
        
        processed_data.append({
            'image': image_normalized,
            'mask': mask_binary,
            'original_image': image_resized
        })
    
    return processed_data

def create_data_loaders(processed_data, train_ratio=0.8):
    """åˆ›å»ºæ•°æ®åŠ è½½å™¨"""
    # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    n_samples = len(processed_data)
    n_train = int(n_samples * train_ratio)
    
    train_data = processed_data[:n_train]
    val_data = processed_data[n_train:]
    
    print(f"è®­ç»ƒé›†: {len(train_data)} æ ·æœ¬")
    print(f"éªŒè¯é›†: {len(val_data)} æ ·æœ¬")
    
    return train_data, val_data

class MoNuSegTransUNet(nn.Module):
    """é’ˆå¯¹MoNuSegä¼˜åŒ–çš„TransUNetæ¨¡å‹"""
    def __init__(self, img_size=512, in_channels=3, out_channels=1):
        super().__init__()
        
        # ç¼–ç å™¨
        self.enc1 = nn.Sequential(
            nn.Conv2d(in_channels, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True)
        )
        
        self.enc2 = nn.Sequential(
            nn.MaxPool2d(2, 2),
            nn.Conv2d(64, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True)
        )
        
        self.enc3 = nn.Sequential(
            nn.MaxPool2d(2, 2),
            nn.Conv2d(128, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True)
        )
        
        self.enc4 = nn.Sequential(
            nn.MaxPool2d(2, 2),
            nn.Conv2d(256, 512, 3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, 3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True)
        )
        
        # è§£ç å™¨
        self.dec4 = nn.Sequential(
            nn.ConvTranspose2d(512, 256, 2, stride=2),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True)
        )
        
        self.dec3 = nn.Sequential(
            nn.ConvTranspose2d(512, 128, 2, stride=2),  # 256+256=512
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True)
        )
        
        self.dec2 = nn.Sequential(
            nn.ConvTranspose2d(256, 64, 2, stride=2),   # 128+128=256
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True)
        )
        
        self.dec1 = nn.Sequential(
            nn.ConvTranspose2d(128, 32, 2, stride=2),   # 64+64=128
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 32, 3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True)
        )
        
        # æœ€ç»ˆè¾“å‡ºå±‚
        self.final_conv = nn.Conv2d(32, out_channels, kernel_size=1)
    
    def forward(self, x):
        input_size = x.size()[2:]
        enc1 = self.enc1(x)
        enc2 = self.enc2(enc1)
        enc3 = self.enc3(enc2)
        enc4 = self.enc4(enc3)
        dec4 = self.dec4(enc4)
        # å¯¹é½enc3å°ºå¯¸
        if dec4.shape[2:] != enc3.shape[2:]:
            dec4 = F.interpolate(dec4, size=enc3.shape[2:], mode='bilinear', align_corners=False)
        dec4 = torch.cat([dec4, enc3], dim=1)
        dec3 = self.dec3(dec4)
        if dec3.shape[2:] != enc2.shape[2:]:
            dec3 = F.interpolate(dec3, size=enc2.shape[2:], mode='bilinear', align_corners=False)
        dec3 = torch.cat([dec3, enc2], dim=1)
        dec2 = self.dec2(dec3)
        if dec2.shape[2:] != enc1.shape[2:]:
            dec2 = F.interpolate(dec2, size=enc1.shape[2:], mode='bilinear', align_corners=False)
        dec2 = torch.cat([dec2, enc1], dim=1)
        dec1 = self.dec1(dec2)
        # è¾“å‡ºresizeåˆ°è¾“å…¥å°ºå¯¸
        if dec1.shape[2:] != input_size:
            dec1 = F.interpolate(dec1, size=input_size, mode='bilinear', align_corners=False)
        output = self.final_conv(dec1)
        return output

def dice_loss(pred, target, smooth=1e-6):
    """DiceæŸå¤±å‡½æ•°"""
    pred = torch.sigmoid(pred)
    
    pred_flat = pred.view(-1)
    target_flat = target.view(-1)
    
    intersection = (pred_flat * target_flat).sum()
    union = pred_flat.sum() + target_flat.sum()
    
    dice = (2. * intersection + smooth) / (union + smooth)
    return 1 - dice

def dice_coefficient(pred, target, smooth=1e-6):
    """è®¡ç®—Diceç³»æ•°"""
    pred = torch.sigmoid(pred) > 0.5
    
    pred_flat = pred.view(-1)
    target_flat = target.view(-1)
    
    intersection = (pred_flat * target_flat).sum()
    union = pred_flat.sum() + target_flat.sum()
    
    dice = (2. * intersection + smooth) / (union + smooth)
    return dice.item()

def train_model(model, train_data, val_data, num_epochs=20, batch_size=2):
    """è®­ç»ƒæ¨¡å‹"""
    print("å¼€å§‹è®­ç»ƒæ¨¡å‹...")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    model = model.to(device)
    criterion = dice_loss
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3)
    
    train_losses = []
    val_losses = []
    best_dice = 0.0
    
    for epoch in range(num_epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0.0
        
        # éšæœºé€‰æ‹©è®­ç»ƒæ ·æœ¬
        indices = np.random.choice(len(train_data), min(batch_size, len(train_data)), replace=False)
        
        for idx in indices:
            sample = train_data[idx]
            
            # å‡†å¤‡æ•°æ®
            image = torch.from_numpy(sample['image'].transpose(2, 0, 1)).unsqueeze(0).to(device)
            mask = torch.from_numpy(sample['mask'].astype(np.float32) / 255.0).unsqueeze(0).unsqueeze(0).to(device)
            
            # å‰å‘ä¼ æ’­
            optimizer.zero_grad()
            output = model(image)
            loss = criterion(output, mask)
            
            # åå‘ä¼ æ’­
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
        
        train_loss /= len(indices)
        train_losses.append(train_loss)
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss = 0.0
        val_dice = 0.0
        
        with torch.no_grad():
            for sample in val_data[:5]:  # åªéªŒè¯å‰5ä¸ªæ ·æœ¬
                image = torch.from_numpy(sample['image'].transpose(2, 0, 1)).unsqueeze(0).to(device)
                mask = torch.from_numpy(sample['mask'].astype(np.float32) / 255.0).unsqueeze(0).unsqueeze(0).to(device)
                
                output = model(image)
                loss = criterion(output, mask)
                dice = dice_coefficient(output, mask)
                
                val_loss += loss.item()
                val_dice += dice
        
        val_loss /= min(5, len(val_data))
        val_dice /= min(5, len(val_data))
        val_losses.append(val_loss)
        
        # å­¦ä¹ ç‡è°ƒåº¦
        scheduler.step(val_loss)
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_dice > best_dice:
            best_dice = val_dice
            torch.save(model.state_dict(), 'best_model.pth')
        
        print(f"Epoch {epoch+1}/{num_epochs}")
        print(f"  è®­ç»ƒæŸå¤±: {train_loss:.4f}")
        print(f"  éªŒè¯æŸå¤±: {val_loss:.4f}")
        print(f"  éªŒè¯Dice: {val_dice:.4f}")
        print(f"  å­¦ä¹ ç‡: {optimizer.param_groups[0]['lr']:.6f}")
    
    print(f"è®­ç»ƒå®Œæˆï¼æœ€ä½³éªŒè¯Dice: {best_dice:.4f}")
    return model, train_losses, val_losses

def evaluate_model(model, test_data):
    """è¯„ä¼°æ¨¡å‹"""
    print("è¯„ä¼°æ¨¡å‹...")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.eval()
    
    dice_scores = []
    
    with torch.no_grad():
        for sample in tqdm(test_data, desc="è¯„ä¼°"):
            image = torch.from_numpy(sample['image'].transpose(2, 0, 1)).unsqueeze(0).to(device)
            mask = torch.from_numpy(sample['mask'].astype(np.float32) / 255.0).unsqueeze(0).unsqueeze(0).to(device)
            
            output = model(image)
            dice = dice_coefficient(output, mask)
            dice_scores.append(dice)
    
    avg_dice = np.mean(dice_scores)
    std_dice = np.std(dice_scores)
    
    print(f"å¹³å‡Diceç³»æ•°: {avg_dice:.4f} Â± {std_dice:.4f}")
    print(f"æœ€é«˜Diceç³»æ•°: {np.max(dice_scores):.4f}")
    print(f"æœ€ä½Diceç³»æ•°: {np.min(dice_scores):.4f}")
    
    return dice_scores

def visualize_results(model, test_data, num_samples=3):
    """å¯è§†åŒ–ç»“æœ"""
    print("ç”Ÿæˆå¯è§†åŒ–ç»“æœ...")
    
    os.makedirs('results', exist_ok=True)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.eval()
    
    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5*num_samples))
    
    for i in range(num_samples):
        if i >= len(test_data):
            break
            
        sample = test_data[i]
        
        # åŸå§‹å›¾åƒ
        axes[i, 0].imshow(sample['original_image'])
        axes[i, 0].set_title('Original Image')
        axes[i, 0].axis('off')
        
        # çœŸå®æ©ç 
        axes[i, 1].imshow(sample['mask'], cmap='gray')
        axes[i, 1].set_title('Ground Truth Mask')
        axes[i, 1].axis('off')
        
        # é¢„æµ‹æ©ç 
        with torch.no_grad():
            image = torch.from_numpy(sample['image'].transpose(2, 0, 1)).unsqueeze(0).to(device)
            output = model(image)
            pred = torch.sigmoid(output) > 0.5
            pred_mask = pred.squeeze().cpu().numpy().astype(np.uint8) * 255
        
        axes[i, 2].imshow(pred_mask, cmap='gray')
        axes[i, 2].set_title('Predicted Mask')
        axes[i, 2].axis('off')
    
    plt.tight_layout()
    plt.savefig('results/monuseg_results.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print("å¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ° results/monuseg_results.png")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¥ MoNuSegåŒ»å­¦å›¾åƒåˆ†å‰²é¡¹ç›®")
    print("=" * 50)
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # æ­¥éª¤1: åŠ è½½è®­ç»ƒæ•°æ®
    train_data_pairs = load_monuseg_data("data", is_training=True)
    
    # æ­¥éª¤2: åŠ è½½æµ‹è¯•æ•°æ®
    test_data_pairs = load_monuseg_data("data/MoNuSegTestData", is_training=False)
    
    # æ­¥éª¤3: é¢„å¤„ç†æ•°æ®
    train_processed = preprocess_data(train_data_pairs)
    test_processed = preprocess_data(test_data_pairs)
    
    # æ­¥éª¤4: åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_data, val_data = create_data_loaders(train_processed)
    
    # æ­¥éª¤5: åˆ›å»ºæ¨¡å‹
    model = MoNuSegTransUNet(img_size=512, in_channels=3, out_channels=1)
    
    # æ­¥éª¤6: è®­ç»ƒæ¨¡å‹
    model, train_losses, val_losses = train_model(model, train_data, val_data, num_epochs=15)
    
    # æ­¥éª¤7: è¯„ä¼°æ¨¡å‹
    dice_scores = evaluate_model(model, test_processed)
    
    # æ­¥éª¤8: å¯è§†åŒ–ç»“æœ
    visualize_results(model, test_processed)
    
    # æ­¥éª¤9: ç»˜åˆ¶è®­ç»ƒæ›²çº¿
    plt.figure(figsize=(12, 4))
    
    plt.subplot(1, 2, 1)
    plt.plot(train_losses, label='Training Loss')
    plt.plot(val_losses, label='Validation Loss')
    plt.title('Training Loss Curves')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)
    
    plt.subplot(1, 2, 2)
    plt.hist(dice_scores, bins=10, alpha=0.7, color='skyblue', edgecolor='black')
    plt.title('Test Set Dice Coefficient Distribution')
    plt.xlabel('Dice Coefficient')
    plt.ylabel('Frequency')
    plt.grid(True)
    
    plt.tight_layout()
    plt.savefig('results/training_curves.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print("\n" + "="*50)
    print("ğŸ‰ é¡¹ç›®è¿è¡Œå®Œæˆï¼")
    print("="*50)
    print(f"æœ€ç»ˆå¹³å‡Diceç³»æ•°: {np.mean(dice_scores):.4f}")
    print("ç»“æœæ–‡ä»¶:")
    print("  - results/monuseg_results.png")
    print("  - results/training_curves.png")
    print("  - best_model.pth")
    print(f"ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

if __name__ == '__main__':
    main() 